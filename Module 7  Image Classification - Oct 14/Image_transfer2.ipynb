{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f842df94-9e9a-4884-b995-73873a0b1896",
   "metadata": {},
   "source": [
    "## Image Classification with Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9a7ef0-21b2-4fc4-9051-c91d4239b10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# deep learning libraries\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import applications\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Flatten, Dense, Dropout\n",
    "from keras.preprocessing import image\n",
    "\n",
    "import cv2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ad28f1-4b53-49fe-92b5-0ec2c59d6327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure File Locations\n",
    "\n",
    "# dataset labels\n",
    "labels = pd.read_csv('Dogs/labels.csv')\n",
    "\n",
    "# folders paths\n",
    "train_path = 'Dogs/train'\n",
    "test_path = 'Dogs/test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37589e0b-a8db-4eb1-9054-21c9dbccbf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b4aac5-b761-468e-be99-46537e07da53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add .jpg extension to id to map to file names\n",
    "\n",
    "def to_jpg(id):\n",
    "    return id+\".jpg\"\n",
    "\n",
    "\n",
    "labels['id'] = labels['id'].apply(to_jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d796289a-0155-4e53-a80f-ae1cf026172c",
   "metadata": {},
   "source": [
    "## The next 3 cells run a data aumentation process to modify the original images for tranfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9043071e-f95f-439a-9646-23c668d81be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data agumentation and pre-processing using tensorflow\n",
    "gen = ImageDataGenerator(\n",
    "                  rescale=1./255.,\n",
    "                  horizontal_flip = True,\n",
    "                  validation_split=0.2 # training: 80% data, validation: 20% data\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a36ca61-58e8-4939-97b1-13e338b7c335",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = gen.flow_from_dataframe(\n",
    "    labels, # dataframe\n",
    "    directory = train_path, # images data path / folder in which images are there\n",
    "    x_col = 'id',\n",
    "    y_col = 'breed',\n",
    "    subset=\"training\",\n",
    "    color_mode=\"rgb\",\n",
    "    target_size = (331,331), # image height , image width\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a1f070-39e6-4014-bd00-436e2d8da272",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator = gen.flow_from_dataframe(\n",
    "    labels, # dataframe\n",
    "    directory = train_path, # images data path / folder in which images are there\n",
    "    x_col = 'id',\n",
    "    y_col = 'breed',\n",
    "    subset=\"validation\",\n",
    "    color_mode=\"rgb\",\n",
    "    target_size = (331,331), # image height , image width\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87105bf6-a537-41b6-84eb-84fa57b365fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(train_generator)\n",
    "x.shape # input shape of one record is (331,331,3) , 32: is the batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101c6fdd-f855-4a4b-a668-6859cd05d568",
   "metadata": {},
   "source": [
    "## Display a batch of training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d34ce02-5296-4a81-adc5-9006e06578c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train_generator.class_indices\n",
    "class_names = list(a.keys())  # storing class/breed names in a list\n",
    "\n",
    "\n",
    "def plot_images(img, labels):\n",
    "    plt.figure(figsize=[15, 10])\n",
    "    for i in range(25):\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        plt.imshow(img[i])\n",
    "        plt.title(class_names[np.argmax(labels[i])])\n",
    "        plt.axis('off')\n",
    "\n",
    "plot_images(x,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d0471e-e9a8-4447-b61f-49661608a367",
   "metadata": {},
   "source": [
    "## Define the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2c03e5-5346-4a56-9a14-37e0d35d53d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the InceptionResNetV2 architecture with imagenet weights as base\n",
    "base_model = tf.keras.applications.InceptionResNetV2(\n",
    "                     include_top=False,\n",
    "                     weights='imagenet',\n",
    "                     input_shape=(331,331,3)\n",
    "                     )\n",
    "\n",
    "base_model.trainable=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c043b5ff-1eed-4564-820d-98a190986d19",
   "metadata": {},
   "source": [
    "## Define the transfer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ef50c1-0a45-46a1-80ba-c4d64c4b4116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model and pass an input with a defined shape \n",
    "# so the model can infer the shapes of all the layers\n",
    "input_tensor = tf.keras.Input(shape=(331,331,3))\n",
    "output_tensor = base_model(input_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132ac342-478e-4622-8fa2-37a452fff761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now build the rest of the model\n",
    "model = tf.keras.Sequential([\n",
    "        base_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(120, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0fe201-6d02-4172-be7c-47be4b9c41e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "# categorical cross entropy is taken since its used as a loss function for \n",
    "# multi-class classification problems where there are two or more output labels.\n",
    "# using Adam optimizer for better performance\n",
    "# other optimizers such as sgd can also be used depending upon the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b727b36-66b3-4e6c-98c3-c6d74684287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cf3423-c584-4009-9aa2-948688457664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A callback is an object that can perform actions at various stages of training \n",
    "# (for example, at the start or end of an epoch, before or after a single batch, etc).\n",
    "early = tf.keras.callbacks.EarlyStopping( patience=10,\n",
    "                                          min_delta=0.001,\n",
    "                                          restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea52f265-aad9-4bd6-81ee-82cebb38ce36",
   "metadata": {},
   "source": [
    "## Train the transfer model to tune it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4bf8fe-2a3d-43c8-950c-24f2678a4ea8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit the model by transfering the old weights to the new data scenario\n",
    "batch_size=32\n",
    "STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID = validation_generator.n//validation_generator.batch_size\n",
    "\n",
    "# fit model\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=25,\n",
    "                    callbacks=[early])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38b9c2f-5685-46ba-b80d-3a4a84518b33",
   "metadata": {},
   "source": [
    "#### The next 2 cells are used to persist and load the results\n",
    "#### We don't want to lose any progress\n",
    "### Note that the two save files have been loaded to web campus for you to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841e849d-56d3-4d07-bcfd-bd185aa58e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persist the model for later use\n",
    "# Use Keras for model and pickle for history\n",
    "import pickle\n",
    "\n",
    "# save the model\n",
    "model.save(\"TransferModel_InceptionResNetV2.keras\")\n",
    "\n",
    "# save the history\n",
    "with open('history.pkl', 'wb') as file: \n",
    "    # A new file will be created \n",
    "    pickle.dump(history, file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2b3c90-e6fe-43d9-9710-ffbf4026bc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how you load the objects of needed:\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Load Model with Keras\n",
    "persistedModel = keras.saving.load_model(\"TransferModel_InceptionResNetV2.keras\")\n",
    "\n",
    "# Load history with pickle\n",
    "with open('history.pkl', 'rb') as file: \n",
    "    # Call load method to deserialze \n",
    "    persistedHistory = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4985315c-6efc-4f06-9dbd-fe1c9ac73894",
   "metadata": {},
   "source": [
    "## Store and display the training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baab2c07-7733-4bf8-9249-72d4156c18da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store results\n",
    "acc = persistedHistory.history['accuracy']\n",
    "val_acc = persistedHistory.history['val_accuracy']\n",
    "loss = persistedHistory.history['loss']\n",
    "val_loss = persistedHistory.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16e30e6-e3e4-41e4-b493-e3f1ef3e4929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n",
    "# accuracy\n",
    "plt.figure(figsize=(8, 12))\n",
    "plt.rcParams['figure.figsize'] = [19,9]\n",
    "plt.rcParams['font.size'] = 8\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(f\"\"\"\\nTraining and Validation Accuracy. \\nTrain Accuracy: \n",
    "          {str(acc[-1])}\\nValidation Accuracy: {str(val_acc[-1])}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4866578c-204c-4a59-9426-38270bff2767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.title(f\"\"\"Training and Validation Loss. \\nTrain Loss: \n",
    "          {str(loss[-1])}\\nValidation Loss: {str(val_loss[-1])}\"\"\")\n",
    "plt.xlabel('epoch')\n",
    "plt.tight_layout(pad=3.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846c176a-5887-456e-b36c-bab718c2d140",
   "metadata": {},
   "source": [
    "#### Validate the model using a batch of images from the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450303e4-08de-4c7c-a66a-7fde22ca1e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score = persistedModel.evaluate(validation_generator)\n",
    "print(accuracy_score)\n",
    "print(\"Accuracy: {:.4f}%\".format(accuracy_score[1] * 100)) \n",
    "\n",
    "print(\"Loss: \",accuracy_score[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f40a0c-b0f1-480e-8885-7aff76afe5d3",
   "metadata": {},
   "source": [
    "## Load and classify a new image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d003f4e-18bf-4efa-b5d8-7dd9536d69d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_path = test_path+'/000621fb3cbb32d8935728e48679680e.jpg'\n",
    "\n",
    "img = cv2.imread(test_img_path)\n",
    "resized_img = cv2.resize(img, (331, 331)).reshape(-1, 331, 331, 3)/255\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.title(\"TEST IMAGE\")\n",
    "plt.imshow(resized_img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43c16ed-4873-49ee-bc04-486eb484aaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img = tf.keras.preprocessing.image.smart_resize(img, (331, 331))\n",
    "img = tf.reshape(img, (-1, 331, 331, 3))\n",
    "prediction = np.argmax(persistedModel.predict(img/255))\n",
    "\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5803daa-59a1-4e81-ada4-6326be73e816",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
